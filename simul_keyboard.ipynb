{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ab941c-53f8-467b-8ad4-0fe44d10c769",
   "metadata": {},
   "source": [
    "1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a83a3-306f-4ba4-b59c-3cd7ef1709e7",
   "metadata": {},
   "source": [
    "1.1 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c37cf-07f2-4053-b056-79b157b4b88d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow matplotlib tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168fc08-022c-49ca-a7ff-7874b831e0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn import preprocessing\n",
    "import random as rn\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, TimeDistributed, Dropout, Bidirectional, GRU, BatchNormalization, Activation, LeakyReLU, LSTM, Flatten, RepeatVector, Permute, Multiply, Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13c47f-76c3-43c6-b048-63b80dd33ce5",
   "metadata": {},
   "source": [
    "2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd226490-6909-4db9-8c6b-240da2158ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94676b38-96b1-4c23-b55d-53b2cd5bbc12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=3072)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7b17f-cc6e-4171-a659-dca32797a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5b60d-6ec9-4e45-9cb6-b6ad6f4c73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('data', 'train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a347db-7204-4092-86cc-bbdb3b0e2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = librosa.load(DATA_DIR + 'Q-01.wav', sr=16000)\n",
    "print('sr:', sr)\n",
    "print('wav shape:', wav.shape)\n",
    "print('length:', wav.shape[0]/float(sr), 'secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ed053-15fa-40ff-8290-3f32e3dd068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw wave\n",
    "print(plt.plot(wav))\n",
    "print(plt.plot(wav[0:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bdb87-9a60-4935-8f31-61da98c92a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mlp = []\n",
    "train_spectrograms = []\n",
    "train_mel_spectrograms = []\n",
    "train_mfccs = []\n",
    "train_y = []\n",
    "\n",
    "test_mlp = []\n",
    "test_spectrograms = []\n",
    "test_mel_spectrograms = []\n",
    "test_mfccs = []\n",
    "test_y = []\n",
    "\n",
    "# 모든 음성파일의 길이가 같도록 후위에 padding 처리\n",
    "pad1d = lambda a, i: a[0: i] if a.shape[0] > i else np.hstack((a, np.zeros(i-a.shape[0])))\n",
    "pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "\n",
    "frame_length = 0.025\n",
    "frame_stride = 0.0010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42108aa-5c3b-42d4-a27f-3c05056f6d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_labels(filename):\n",
    "  if filename[0] == 'Q':\n",
    "    return 0\n",
    "  elif filename[0] == 'W':\n",
    "    return 1\n",
    "  elif filename[0] == 'E':\n",
    "    return 2\n",
    "  elif filename[0] == 'R':\n",
    "    return 3\n",
    "  else:\n",
    "    return 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e6132",
   "metadata": {},
   "source": [
    "Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c78e31-fd53-44ff-887a-78c252587a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(filename):\n",
    "    wav, sr = librosa.load(filename, sr=16000)\n",
    "    spectrogram = np.abs(librosa.stft(wav))\n",
    "    padded_spectrogram = pad2d(spectrogram, 40)\n",
    "    return padded_spectrogram\n",
    "\n",
    "# Step 1: Create a dictionary where keys are labels and values are lists of spectrograms.\n",
    "spectrograms_by_label = defaultdict(list)\n",
    "\n",
    "# Step 2: For each filename in the directory, get the spectrogram and label, and append the spectrogram to the corresponding list in the dictionary.\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    if '.wav' not in filename:\n",
    "        continue\n",
    "\n",
    "    spectrogram = get_spectrogram(DATA_DIR + filename)\n",
    "    label = get_labels(filename)\n",
    "\n",
    "    spectrograms_by_label[label].append(spectrogram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d747d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 and 4: For each label in the dictionary, apply the train_test_split function to create separate train and test sets. Store the train and test sets for each label in separate dictionaries.\n",
    "train_spectrograms_by_label = {}\n",
    "test_spectrograms_by_label = {}\n",
    "train_labels_by_label = {}\n",
    "test_labels_by_label = {}\n",
    "for label, spectrograms in spectrograms_by_label.items():\n",
    "    train_spectrograms, test_spectrograms = train_test_split(spectrograms, test_size=0.2, random_state=42)\n",
    "    train_spectrograms_by_label[label] = train_spectrograms\n",
    "    test_spectrograms_by_label[label] = test_spectrograms\n",
    "    train_labels_by_label[label] = [label] * len(train_spectrograms)\n",
    "    test_labels_by_label[label] = [label] * len(test_spectrograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8128da2b",
   "metadata": {},
   "source": [
    "Spectogram feature training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b645562",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spectrograms = np.expand_dims(train_spectrograms, -1)\n",
    "test_spectrograms = np.expand_dims(test_spectrograms, -1)\n",
    "print('train_spectograms shape:', train_spectrograms.shape)\n",
    "print('test_spectograms shape:', test_spectrograms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d0994",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = Input(shape=train_spectrograms[0].shape)\n",
    "\n",
    "m = Conv2D(32, kernel_size=(4,4), activation='relu')(ip)\n",
    "m = MaxPooling2D(pool_size=(4,4))(m)\n",
    "\n",
    "m = Conv2D(32*2, kernel_size=(4,4), activation='relu')(ip)\n",
    "m = MaxPooling2D(pool_size=(4,4))(m)\n",
    "\n",
    "m = Conv2D(32 * 3, kernel_size=(4, 4), activation='relu')(ip)\n",
    "m = MaxPooling2D(pool_size=(4,4))(m)\n",
    "\n",
    "m = Flatten()(m)\n",
    "\n",
    "m = Dense(64, activation='relu')(m)\n",
    "\n",
    "m = Dense(32, activation='relu')(m)\n",
    "\n",
    "op = Dense(4, activation='softmax')(m)\n",
    "\n",
    "model = Model(ip, op)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd91b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_spectrograms,\n",
    "                    train_y,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_spectrograms, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe561744",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (DATA_DIR + 'Q-30.wav')\n",
    "spectrogram = get_spectrogram(filename)\n",
    "spectrogram = np.expand_dims(spectrogram, 0)\n",
    "prediction = model.predict(spectrogram)\n",
    "plt.bar([\"Q\", \"W\", \"E\", \"R\", \"S\"], tf.nn.softmax(prediction[0]))\n",
    "plt.title('Q')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee619ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (DATA_DIR + 'W-30.wav')\n",
    "spectrogram = get_spectrogram(filename)\n",
    "spectrogram = np.expand_dims(spectrogram, 0)\n",
    "prediction = model.predict(spectrogram)\n",
    "plt.bar([\"Q\", \"W\", \"E\", \"R\", \"S\"], tf.nn.softmax(prediction[0]))\n",
    "plt.title('W')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd43593",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (DATA_DIR + 'E-30.wav')\n",
    "spectrogram = get_spectrogram(filename)\n",
    "spectrogram = np.expand_dims(spectrogram, 0)\n",
    "prediction = model.predict(spectrogram)\n",
    "plt.bar([\"Q\", \"W\", \"E\", \"R\", \"S\"], tf.nn.softmax(prediction[0]))\n",
    "plt.title('E')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (DATA_DIR + 'R-30.wav')\n",
    "spectrogram = get_spectrogram(filename)\n",
    "spectrogram = np.expand_dims(spectrogram, 0)\n",
    "prediction = model.predict(spectrogram)\n",
    "plt.bar([\"Q\", \"W\", \"E\", \"R\", \"S\"], tf.nn.softmax(prediction[0]))\n",
    "plt.title('R')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (DATA_DIR + 'S-30.wav')\n",
    "spectrogram = get_spectrogram(filename)\n",
    "spectrogram = np.expand_dims(spectrogram, 0)\n",
    "prediction = model.predict(spectrogram)\n",
    "plt.bar([\"Q\", \"W\", \"E\", \"R\", \"S\"], tf.nn.softmax(prediction[0]))\n",
    "plt.title('S')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba6a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
